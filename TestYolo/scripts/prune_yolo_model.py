#!/usr/bin/env python3
"""
YOLOv8 Channel Pruning Script

–ü—Ä–∏–º–µ–Ω—è–µ—Ç structured pruning –∫ YOLOv8 –º–æ–¥–µ–ª–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –ø–∞–¥–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
    pip install ultralytics torch-pruning

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python prune_yolo_model.py --model yolov8n.pt --ratio 0.2 --epochs 10
    
    –≠—Ç–æ —Å–æ–∑–¥–∞—Å—Ç:
    - yolov8n_pruned.pt (PyTorch –º–æ–¥–µ–ª—å)
    - yolov8n_pruned.onnx (ONNX –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏)
"""

import argparse
from pathlib import Path


def check_dependencies():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"""
    missing = []
    
    try:
        import torch
    except ImportError:
        missing.append('torch')
    
    try:
        from ultralytics import YOLO
    except ImportError:
        missing.append('ultralytics')
    
    try:
        import torch_pruning
    except ImportError:
        missing.append('torch-pruning')
    
    if missing:
        print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:")
        print(f"   pip install {' '.join(missing)}")
        return False
    return True


def prune_yolov8(
    model_path: str,
    pruning_ratio: float = 0.2,
    finetune_epochs: int = 10,
    data_yaml: str = 'coco128.yaml',
    imgsz: int = 640,
    output_dir: str = './pruned_models'
):
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç channel pruning –∫ YOLOv8 –º–æ–¥–µ–ª–∏.
    
    Args:
        model_path: –ü—É—Ç—å –∫ .pt –º–æ–¥–µ–ª–∏
        pruning_ratio: –î–æ–ª—è –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (0.2 = 20%)
        finetune_epochs: –≠–ø–æ—Ö–∏ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
        data_yaml: –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è fine-tuning
        imgsz: –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    import torch
    import torch_pruning as tp
    from ultralytics import YOLO
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print(f"\n{'='*60}")
    print(f"üî™ YOLOv8 Channel Pruning")
    print(f"{'='*60}")
    print(f"–ú–æ–¥–µ–ª—å:          {model_path}")
    print(f"Pruning ratio:   {pruning_ratio*100:.0f}%")
    print(f"Fine-tune epochs: {finetune_epochs}")
    print(f"Dataset:         {data_yaml}")
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model = YOLO(model_path)
    
    # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    pytorch_model = model.model
    
    # –ü–æ–¥—Å—á—ë—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–æ pruning
    params_before = sum(p.numel() for p in pytorch_model.parameters())
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–æ pruning: {params_before:,} ({params_before/1e6:.2f}M)")
    
    # 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ pruner
    print("\nüîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ pruner...")
    
    # –ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–∞ –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –≥—Ä–∞—Ñ–∞
    example_inputs = torch.randn(1, 3, imgsz, imgsz).to(next(pytorch_model.parameters()).device)
    
    # –°–ª–æ–∏, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –Ω—É–∂–Ω–æ –æ–±—Ä–µ–∑–∞—Ç—å (detection heads –∏ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ)
    ignored_layers = []
    for name, module in pytorch_model.named_modules():
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º detection heads
        if 'detect' in name.lower() or 'cv2' in name or 'cv3' in name:
            ignored_layers.append(module)
    
    # Importance scorer –Ω–∞ –æ—Å–Ω–æ–≤–µ L1-–Ω–æ—Ä–º—ã –≤–µ—Å–æ–≤
    importance = tp.importance.MagnitudeImportance(p=1)  # L1 norm
    
    # –°–æ–∑–¥–∞—ë–º pruner
    pruner = tp.pruner.MagnitudePruner(
        pytorch_model,
        example_inputs=example_inputs,
        importance=importance,
        pruning_ratio=pruning_ratio,
        ignored_layers=ignored_layers,
        round_to=8,  # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ –∫—Ä–∞—Ç–Ω–æ–≥–æ 8 –¥–ª—è SIMD
    )
    
    # 3. –ü—Ä–∏–º–µ–Ω—è–µ–º pruning
    print("\n‚úÇÔ∏è  –ü—Ä–∏–º–µ–Ω—è–µ–º pruning...")
    pruner.step()
    
    # –ü–æ–¥—Å—á—ë—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ—Å–ª–µ pruning
    params_after = sum(p.numel() for p in pytorch_model.parameters())
    reduction = (1 - params_after / params_before) * 100
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ—Å–ª–µ pruning: {params_after:,} ({params_after/1e6:.2f}M)")
    print(f"–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ: {reduction:.1f}%")
    
    # 4. Fine-tuning
    if finetune_epochs > 0:
        print(f"\nüéØ Fine-tuning –Ω–∞ {finetune_epochs} —ç–ø–æ—Ö–∞—Ö...")
        model.train(
            data=data_yaml,
            epochs=finetune_epochs,
            imgsz=imgsz,
            batch=16,
            patience=5,
            pretrained=False,  # –£–∂–µ –µ—Å—Ç—å –≤–µ—Å–∞
            optimizer='AdamW',
            lr0=0.001,
            warmup_epochs=1,
            cos_lr=True,
        )
    
    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    pruned_name = Path(model_path).stem + '_pruned'
    
    # PyTorch
    pt_path = output_path / f"{pruned_name}.pt"
    model.save(str(pt_path))
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {pt_path}")
    
    # ONNX –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ ncnn
    onnx_path = output_path / f"{pruned_name}.onnx"
    model.export(format='onnx', imgsz=imgsz, simplify=True)
    print(f"üíæ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {onnx_path}")
    
    # 6. –í–∞–ª–∏–¥–∞—Ü–∏—è
    print("\nüìä –í–∞–ª–∏–¥–∞—Ü–∏—è pruned –º–æ–¥–µ–ª–∏...")
    metrics = model.val(data=data_yaml, imgsz=imgsz)
    print(f"mAP50: {metrics.box.map50:.4f}")
    print(f"mAP50-95: {metrics.box.map:.4f}")
    
    print(f"\n{'='*60}")
    print("‚úÖ Pruning –∑–∞–≤–µ—Ä—à—ë–Ω!")
    print(f"{'='*60}")
    print("\n–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ –¥–ª—è Android:")
    print("1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ncnn tools:")
    print("   git clone https://github.com/Tencent/ncnn && cd ncnn && mkdir build && cd build")
    print("   cmake .. && make -j$(nproc)")
    print("\n2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–π—Ç–µ ONNX ‚Üí ncnn:")
    print(f"   ./onnx2ncnn {onnx_path} {pruned_name}.param {pruned_name}.bin")
    print(f"\n3. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤ assets:")
    print(f"   cp {pruned_name}.param {pruned_name}.bin app/src/main/assets/")
    
    return model, metrics


def main():
    parser = argparse.ArgumentParser(description='YOLOv8 Channel Pruning')
    parser.add_argument('--model', '-m', default='yolov8n.pt',
                        help='Path to YOLOv8 model (.pt)')
    parser.add_argument('--ratio', '-r', type=float, default=0.2,
                        help='Pruning ratio (0.2 = remove 20%% channels)')
    parser.add_argument('--epochs', '-e', type=int, default=10,
                        help='Fine-tuning epochs (0 to skip)')
    parser.add_argument('--data', '-d', default='coco128.yaml',
                        help='Dataset for fine-tuning')
    parser.add_argument('--imgsz', type=int, default=640,
                        help='Image size')
    parser.add_argument('--output', '-o', default='./pruned_models',
                        help='Output directory')
    
    args = parser.parse_args()
    
    if not check_dependencies():
        return 1
    
    prune_yolov8(
        model_path=args.model,
        pruning_ratio=args.ratio,
        finetune_epochs=args.epochs,
        data_yaml=args.data,
        imgsz=args.imgsz,
        output_dir=args.output
    )
    
    return 0


if __name__ == '__main__':
    exit(main())
